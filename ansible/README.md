# Ansible Configuration for Kubernetes Cluster

Automated Kubernetes cluster configuration using Ansible playbooks and roles.

## Directory Structure

```
ansible/
├── playbooks/          # Ansible playbooks (executed in order)
│   ├── prerequisites.yml             # Install Python dependencies
│   ├── configure-nodes.yml           # Configure all nodes
│   ├── initialize-control-plane.yml  # Initialize control plane
│   ├── join-worker-nodes.yml         # Join worker nodes
│   ├── deploy-metallb.yml            # Deploy MetalLB
│   ├── deploy-argocd.yml             # Deploy ArgoCD
│   └── cleanup.yml                   # Cleanup cluster
├── roles/             # Reusable Ansible roles
│   ├── firewall/                     # UFW firewall configuration
│   ├── system-prep/                  # System preparation
│   ├── container-runtime/            # Containerd installation
│   ├── kubernetes/                   # Kubernetes components
│   └── networking/                   # Network fixes
├── templates/         # Jinja2 templates
│   ├── inventory.tftpl               # Inventory template
│   └── kubeadm-config.yml.j2         # Kubeadm config template
├── group_vars/        # Group variables
│   ├── all.yml                       # Auto-generated by Terraform
│   └── vault.yml.example             # Vault example
├── ansible.cfg        # Ansible configuration
└── hosts.ini          # Inventory file (auto-generated by Terraform)
```

## Auto-Generated Files

The following files are automatically generated by Terraform:
- `hosts.ini` - Ansible inventory with control plane and worker IPs
- `group_vars/all.yml` - Variables including versions and network configuration

## Playbook Execution Order

The playbooks must be executed in this specific order:

### Phase 1: Prerequisites
**prerequisites.yml** - Install Python packages required for Ansible Kubernetes modules
- Target: All nodes
- Prerequisites: None
- What it does: Install Python, pip, kubernetes library, yaml library
- Why: Ansible needs Python dependencies to manage Kubernetes resources

### Phase 2: Node Configuration
**configure-nodes.yml** - Configure nodes for Kubernetes
- Target: All nodes (control plane + workers)
- Prerequisites: Python dependencies installed
- What it does: Firewall, swap disable, kernel modules, containerd, kubeadm/kubelet/kubectl
- Why: All nodes need identical base configuration before cluster initialization

### Phase 3: Cluster Initialization
**initialize-control-plane.yml** - Initialize Kubernetes cluster
- Target: Control plane node
- Prerequisites: All nodes configured
- What it does: kubeadm init, CNI (Calico), kubelet-csr-approver
- Why: Creates the cluster that workers will join

### Phase 4: Cluster Expansion
**join-worker-nodes.yml** - Join worker nodes to cluster
- Target: Worker nodes
- Prerequisites: Control plane initialized
- What it does: Generate join token, execute kubeadm join on workers
- Why: Expands cluster capacity before deploying workloads

### Phase 5: Infrastructure Services
**deploy-metallb.yml** - Deploy MetalLB for LoadBalancer services
- Target: Control plane (kubectl commands)
- Prerequisites: **Workers joined to cluster**
- What it does: Install MetalLB with IP address pool and L2 advertisement
- Why: LoadBalancer services needed before deploying applications

### Phase 6: GitOps Infrastructure
**deploy-argocd.yml** - Deploy ArgoCD for GitOps
- Target: Control plane (kubectl commands)
- Prerequisites: **MetalLB deployed**
- What it does: Install ArgoCD, configure app-of-apps pattern
- Why: GitOps should be deployed on a fully operational cluster with LoadBalancer services

### Automatic Execution (via Terraform)

When `auto_run_ansible = true` in Terraform:
1. VMs are created
2. Playbooks run automatically in sequence
3. Cluster is ready when Terraform completes

### Manual Execution

```bash
cd ansible

# Phase 1: Prerequisites
ansible-playbook -i hosts.ini playbooks/prerequisites.yml

# Phase 2: Node Configuration
ansible-playbook -i hosts.ini playbooks/configure-nodes.yml

# Phase 3: Cluster Initialization
ansible-playbook -i hosts.ini playbooks/initialize-control-plane.yml

# Phase 4: Cluster Expansion
ansible-playbook -i hosts.ini playbooks/join-worker-nodes.yml

# Phase 5: Infrastructure Services
ansible-playbook -i hosts.ini playbooks/deploy-metallb.yml

# Phase 6: GitOps Infrastructure
ansible-playbook -i hosts.ini playbooks/deploy-argocd.yml
```

## Ansible Roles

### firewall
Configures UFW firewall rules for Kubernetes:
- SSH access
- Kubernetes API server (6443)
- etcd (2379-2380)
- Kubelet API (10250)
- Calico networking (BGP, VXLAN)
- NodePort services (30000-32767)

### system-prep
Prepares the system for Kubernetes:
- Disables swap
- Loads kernel modules (overlay, br_netfilter)
- Configures sysctl parameters
- Enables IP forwarding

### container-runtime
Installs and configures containerd:
- Installs containerd package
- Generates default configuration
- Enables SystemdCgroup
- Starts containerd service

### kubernetes
Installs Kubernetes components:
- Adds Kubernetes APT repository
- Installs kubeadm, kubelet, kubectl
- Holds packages at current version
- Enables kubelet service

### networking
Applies network fixes:
- Disables TX checksum offload for Calico VXLAN
- Creates systemd service for network fixes

## Configuration

### Ansible Vault (Secrets Management)

1. Copy vault example:
```bash
cp group_vars/vault.yml.example group_vars/vault.yml
```

2. Edit vault file:
```bash
ansible-vault edit group_vars/vault.yml
```

3. Add vault password when running playbooks:
```bash
ansible-playbook -i hosts.ini playbooks/01-prepare-nodes.yml --ask-vault-pass
```

### Custom Variables

Edit `group_vars/all.yml` (or better yet, update Terraform variables which auto-generate this file):
- `kubernetes_version`: Kubernetes version to install
- `calico_version`: Calico CNI version
- `pod_network_cidr`: Pod network CIDR
- `desired_dns_servers`: DNS servers for cluster
- `metallb_ip_range`: IP range for MetalLB

## Common Tasks

### Verify Inventory
```bash
ansible-inventory -i hosts.ini --list
```

### Test Connectivity
```bash
ansible all -i hosts.ini -m ping
```

### Check Syntax
```bash
ansible-playbook --syntax-check playbooks/*.yml
```

### Dry Run
```bash
ansible-playbook -i hosts.ini playbooks/01-prepare-nodes.yml --check
```

### Run Specific Role
```bash
ansible-playbook -i hosts.ini playbooks/01-prepare-nodes.yml --tags firewall
```

## Troubleshooting

### SSH Key Issues
```bash
# Test SSH access
ansible all -i hosts.ini -m ping --private-key ~/.ssh/id_rsa

# Add SSH key to known_hosts
ssh-keyscan <node-ip> >> ~/.ssh/known_hosts
```

### Privilege Escalation
```bash
# Use sudo password
ansible-playbook -i hosts.ini playbooks/01-prepare-nodes.yml --ask-become-pass
```

### View Ansible Logs
```bash
tail -f ansible.log
```

### Debug Mode
```bash
ansible-playbook -i hosts.ini playbooks/01-prepare-nodes.yml -vvv
```

## Cleanup

To reset the cluster:
```bash
ansible-playbook -i hosts.ini playbooks/999-cleanup.yml
```

**Warning**: This will destroy the cluster and remove all Kubernetes components!
