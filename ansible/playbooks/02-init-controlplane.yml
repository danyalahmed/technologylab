---
# ============================================================================
# INITIALIZE KUBERNETES CONTROL PLANE
# ============================================================================
# This playbook initializes the Kubernetes control plane on the first master node.
#
# Steps:
#   1. Initialize kubeadm with custom configuration
#   2. Configure kubectl for the ansible user
#   3. Fix CoreDNS configuration for custom DNS servers
#   4. Manually approve initial kubelet CSRs
#   5. Install Calico CNI with Tigera operator
#   6. Deploy kubelet-csr-approver for automatic CSR approval
#   7. Deploy MetalLB for LoadBalancer services
#
# Prerequisites:
#   - All nodes must be prepared (playbook 01)
#
# Post-initialization:
#   - Kubeconfig is available at ~/.kube/config on control plane
#   - Kubeconfig is fetched to ansible/playbooks/temp_kubeconfig
#
# Usage:
#   ansible-playbook -i hosts.ini playbooks/02-init-controlplane.yml
# ============================================================================

- name: Initialize Kubernetes Control Plane
  hosts: controlplane
  become: true
  become_method: ansible.builtin.sudo
  tasks:
    - name: Check if Kubernetes is already installed
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: kube_init_check

    - name: Create kubeadm-config.yaml
      ansible.builtin.template:
        src: kubeadm-config.yml.j2
        dest: "/tmp/kubeadm-config.yaml"
        owner: root
        mode: '0600'
      when: not kube_init_check.stat.exists

    - name: Initialize kubeadm
      ansible.builtin.command:
        cmd: kubeadm init --config /tmp/kubeadm-config.yaml --v=5
      args:
        creates: /etc/kubernetes/admin.conf
      when: not kube_init_check.stat.exists

    - name: Create .kube directory
      ansible.builtin.file:
        path: /home/{{ ansible_user }}/.kube
        state: directory
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        mode: '0755'

    - name: Copy admin.conf to user's kube config
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/{{ ansible_user }}/.kube/config
        owner: "{{ ansible_user }}"
        group: "{{ ansible_user }}"
        remote_src: true
        mode: '0644'

    - name: Get CoreDNS ConfigMap
      kubernetes.core.k8s_info:
        kind: ConfigMap
        name: coredns
        namespace: kube-system
      register: coredns_cm
      become: false

    - name: Build desired Corefile
      ansible.builtin.set_fact:
        corefile_new: "{{ coredns_cm.resources[0].data.Corefile | replace('forward . /etc/resolv.conf', 'forward . ' ~ desired_dns_servers) }}"
      become: false

    - name: Update CoreDNS ConfigMap if different
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: coredns
            namespace: kube-system
          data:
            Corefile: "{{ corefile_new }}"
        state: present
      when: coredns_cm.resources[0].data.Corefile != corefile_new
      register: coredns_apply
      become: false

    - name: Restart CoreDNS deployment if config changed
      ansible.builtin.shell: |
        kubectl rollout restart -n kube-system deployment/coredns
      when: coredns_apply is defined and coredns_apply.changed
      become: false
      changed_when: coredns_apply is defined and coredns_apply.changed

    # --- ONE-TIME MANUAL APPROVAL ---
    # This breaks the "identity loop" so the Kubelet can start the network
    # We use '|| true' because if grep finds nothing, it shouldn't crash the task
    - name: Manually approve initial Kubelet CSRs
      ansible.builtin.shell: |
        set -o pipefail
        kubectl get csr | (grep Pending || true) | awk '{print $1}' | xargs -r kubectl certificate approve
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      changed_when: false
      when: kube_init_check.stat.exists

    - name: Install Calico with Tigera Operator
      become: false
      ansible.builtin.shell: |
        set -o pipefail
        kubectl create namespace calico-system --dry-run=client -o yaml | kubectl apply -f -
        kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/{{ calico_version }}/manifests/tigera-operator.yaml
        sleep 5

        # Patch CIDR, and Apply Custom Resources
        curl -sL https://raw.githubusercontent.com/projectcalico/calico/{{ calico_version }}/manifests/custom-resources.yaml | \
        sed 's|192.168.0.0/16|{{ pod_network_cidr }}|g' | \
        kubectl apply -f -
      changed_when: false

    - name: Fetch kubeconfig to local machine
      ansible.builtin.fetch:
        src: /etc/kubernetes/admin.conf
        dest: "./temp_kubeconfig"
        flat: true # Keeps it from creating a deep directory structure
      become: true
      when: kube_init_check.stat.exists

    - name: Add kubelet-csr-approver chart repo
      ansible.builtin.shell: |
        helm repo add kubelet-csr-approver https://postfinance.github.io/kubelet-csr-approver
        helm repo update
      delegate_to: localhost
      become: false
      changed_when: false

    # issues with helm 4 and ansible kubernetes.core.helm module
    # - name: Deploy kubelet-csr-approver
    #   kubernetes.core.helm:
    #     name: kubelet-csr-approver
    #     chart_ref: kubelet-csr-approver/kubelet-csr-approver
    #     release_namespace: kube-system
    #     kubeconfig: "./temp_kubeconfig"
    #     values:
    #       providerRegex: "{{ kubelet_csr_regex }}"
    #       providerIpPrefixes: "{{ kubelet_csr_ip_prefixes }}"
    #       maxExpirationSeconds: 86400
    #       bypassDnsResolution: true
    #   delegate_to: localhost
    #   become: false

    - name: Deploy kubelet-csr-approver
      ansible.builtin.shell: |
        helm upgrade --install kubelet-csr-approver kubelet-csr-approver/kubelet-csr-approver \
          --namespace kube-system \
          --kubeconfig ./temp_kubeconfig \
          --set providerRegex={{ kubelet_csr_regex | quote }} \
          --set providerIpPrefixes={{ kubelet_csr_ip_prefixes | quote }} \
          --set maxExpirationSeconds=86400 \
          --set bypassDnsResolution=true
      delegate_to: localhost
      become: false
      changed_when: false
      # This ensures Ansible doesn't try to run this if the Master init failed
      when: kube_init_check is defined
    - name: Ensure MetalLB namespace exists
      kubernetes.core.k8s:
        api_version: v1
        kind: Namespace
        name: metallb-system
        state: present
      become: false

    - name: Apply MetalLB manifests
      kubernetes.core.k8s:
        state: present
        src: "https://raw.githubusercontent.com/metallb/metallb/{{ metallb_version }}/config/manifests/metallb-native.yaml"
      become: false

    - name: Configure MetalLB IPAddressPool
      kubernetes.core.k8s:
        definition:
          apiVersion: metallb.io/v1beta1
          kind: IPAddressPool
          metadata:
            namespace: metallb-system
            name: metallb-ip-pool
          spec:
            addresses:
              - "{{ metallb_ip_range }}"
        state: present
      become: false

    - name: Configure MetalLB L2Advertisement
      kubernetes.core.k8s:
        definition:
          apiVersion: metallb.io/v1beta1
          kind: L2Advertisement
          metadata:
            namespace: metallb-system
            name: metallb-l2-advertisement
          spec:
            ipAddressPools:
              - metallb-ip-pool
        state: present
      become: false
